{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fuzzy-ocean",
   "metadata": {},
   "source": [
    "# Tweb Journal Paper: ColBERT-PRF: Semantic Pseudo-Relevance Feedback for Dense Passage and Document Retrieval\n",
    "\n",
    "This notebook demonstrates the experiments in our Tweb journal paper, including:\n",
    "\n",
    "- Experiment for Measuring the Informativeness of Expansion Embeddings of ColBERT-PRF;\n",
    "- Experiment for Efficient Variants of ColBERT-PRF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-example",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install pyt_colbert installs PyTerrier too. You also need to have [FAISS installed](https://github.com/facebookresearch/faiss/blob/main/INSTALL.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "psychological-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 25 16:33:54 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.74       Driver Version: 470.74       CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:DB:00.0 Off |                  N/A |\r\n",
      "| 41%   43C    P8    23W / 280W |    662MiB / 24220MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cutting-border",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.8.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "pt.init()\n",
    "from pyterrier.measures import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-politics",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We have an existing index for the MSMARCO v1 Passage corpus, previously indexed using pyt_colbert (this adds the tokenids file, which is needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dense-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 25, 16:34:06] #> Loading model checkpoint.\n",
      "[Sep 25, 16:34:06] #> Loading checkpoint /nfs/xiao/GOOD_MODELS/colbert.dnn\n",
      "[Sep 25, 16:34:07] #> checkpoint['epoch'] = 0\n",
      "[Sep 25, 16:34:07] #> checkpoint['batch'] = 44500\n"
     ]
    }
   ],
   "source": [
    "from pyterrier_colbert.ranking import ColBERTFactory\n",
    "\n",
    "factory = ColBERTFactory(\n",
    "    \"/colbert_checkpoint_path/colbert.dnn\",\n",
    "    \"/path/to/indices/colbert_passage/\",\"index_name3\",memtype='mem'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-insured",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "This is the default ColBERT dense retrieval setting - a set ANN retrieval from the FAISS index, followed an exact scoring using the large ColBERT index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "together-formation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 25, 16:34:12] #> Loading the FAISS index from /nfs/craigm/indices/colbert_passage/index_name3/ivfpq.faiss ..\n",
      "[Sep 25, 16:34:26] #> Building the emb2pid mapping..\n",
      "[Sep 25, 16:35:01] len(self.emb2pid) = 687989391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading index shards to memory:   0%|          | 0/24 [00:00<?, ?shard/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|██████████| 24/24 [02:33<00:00,  6.40s/shard]\n"
     ]
    }
   ],
   "source": [
    "factory.faiss_index_on_gpu = True\n",
    "e2e = factory.end_to_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "earned-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qrels2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2019')\n",
    "topics2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2019')\n",
    "\n",
    "topics2020 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020')\n",
    "qrels2020 = pt.get_dataset(  \"trec-deep-learning-passages\").get_qrels('test-2020')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-refund",
   "metadata": {},
   "source": [
    "# Experiments for ColBERT-PRF variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tight-commercial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 25, 16:38:10] #> Building the emb2tid mapping..\n",
      "687989391\n",
      "Loading doclens\n"
     ]
    }
   ],
   "source": [
    "fnt=factory.nn_term(df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "relevant-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30522/30522 [00:00<00:00, 143230.96it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "num_docs=fnt.num_docs\n",
    "num_all_tokens = len(fnt.emb2tid) \n",
    "idfdict = {}\n",
    "ictfdict = {}\n",
    "for tid in pt.tqdm(range(fnt.inference.query_tokenizer.tok.vocab_size)):\n",
    "    df = fnt.getDF_by_id(tid)\n",
    "    # for add one IDF score\n",
    "    idfscore = np.log((1+num_docs)/(df+1))\n",
    "    idfdict[tid] = idfscore\n",
    "    # for ICTF score\n",
    "    cf = fnt.getCTF_by_id(tid)\n",
    "    ictfscore = np.log((num_all_tokens+1)/(cf+1))\n",
    "    ictfdict[tid] = ictfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "closing-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30522/30522 [47:20<00:00, 10.75it/s] \n"
     ]
    }
   ],
   "source": [
    "embs_to_analyse = 10_000_000 # the number of tokens to analyse\n",
    "import torch\n",
    "id2meancos = {}\n",
    "for tid in pt.tqdm(range(fnt.inference.query_tokenizer.tok.vocab_size)):\n",
    "    occurrences = torch.where(fnt.emb2tid[0:embs_to_analyse] == tid)\n",
    "    if len(occurrences[0] > 0):\n",
    "        all101 = factory.rrm.part_mmap[0].mmap[occurrences]\n",
    "        all101Mean = all101.mean(0)\n",
    "        mean_cos = torch.nn.functional.cosine_similarity(all101Mean.unsqueeze(0), \n",
    "                                                         all101.clone().type(torch.DoubleTensor)).mean()\n",
    "        id2meancos[tid] = mean_cos.item()\n",
    "    else:\n",
    "        id2meancos[tid] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dress-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pyterrier.transformer import TransformerBase\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pyterrier.transformer import TransformerBase\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "def get_nearest_tokens_for_emb(self, emb, k=10, low_tf=0):\n",
    "    \"\"\"\n",
    "        Displays the most related terms for each query\n",
    "    \"\"\"\n",
    "    scores, ids = self.faiss_index.faiss_index.search(np.array([emb]), k=k)\n",
    "    id2freq = defaultdict(int)\n",
    "    for id_set in ids:\n",
    "        for id in id_set:\n",
    "            id2freq[self.emb2tid[id].item()] += 1\n",
    "    skips = set(self.inference.query_tokenizer.tok.special_tokens_map.values())\n",
    "    rtr = {}\n",
    "    for t, freq in sorted(id2freq.items(), key=lambda item: -1* item[1]):\n",
    "        if freq <= low_tf:\n",
    "            continue\n",
    "        token = self.inference.query_tokenizer.tok.decode([t])\n",
    "        if \"[unused\" in token or token in skips:\n",
    "            continue\n",
    "        rtr[token] = freq\n",
    "    return rtr\n",
    "        \n",
    "def rmv_padding(prf_embs):\n",
    "    outputs =torch.empty([0,prf_embs.shape[1]])\n",
    "    for emb in prf_embs:\n",
    "        if emb.float().sum() == 0:\n",
    "            continue\n",
    "        else:\n",
    "            outputs = torch.cat((outputs,emb.unsqueeze(0)))\n",
    "    return outputs\n",
    "\n",
    "class ColbertPRF_variants(pt.Transformer):\n",
    "    def __init__(self, k, exp_terms, beta=1, r = 42, mean_cos_weight=False, idf_weight=False, ictf_weight=False,return_docs = False, fb_docs=10, kmeans=False,kmedoids=False, kmeansclosest=False,*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.k = k\n",
    "        self.exp_terms = exp_terms\n",
    "        self.beta = beta\n",
    "        self.mean_cos_weight = mean_cos_weight\n",
    "        self.idf_weight = idf_weight\n",
    "        self.ictf_weight = ictf_weight\n",
    "        self.return_docs = return_docs\n",
    "        self.fb_docs = fb_docs\n",
    "        self.r = r\n",
    "        self.kmedoids = kmedoids\n",
    "        self.kmeansclosest = kmeansclosest\n",
    "        self.kmeans = kmeans\n",
    "        assert self.k > self.exp_terms ,\"exp_terms should be smaller than number of clusters\"\n",
    "\n",
    "\n",
    "    def KMeans_clustering(self,prf_embs):\n",
    "        kmn =  KMeans(self.k, random_state=self.r)\n",
    "        kmn.fit(prf_embs)\n",
    "        \n",
    "        emb_and_score = []\n",
    "        for cluster in range(self.k):\n",
    "            # take the centroid, needs to be the float32.\n",
    "            centroid = np.float32( kmn.cluster_centers_[cluster] )\n",
    "            tok2freq = get_nearest_tokens_for_emb(fnt, centroid)\n",
    "            if len(tok2freq) == 0:\n",
    "                continue\n",
    "            most_likely_tok = max(tok2freq, key=tok2freq.get)\n",
    "            tid = fnt.inference.query_tokenizer.tok.convert_tokens_to_ids(most_likely_tok)\n",
    "            \n",
    "            if self.mean_cos_weight:\n",
    "                emb_and_score.append( (centroid, most_likely_tok, tid, id2meancos[tid])) \n",
    "            elif self.idf_weight:\n",
    "                emb_and_score.append( (centroid, most_likely_tok, tid, idfdict[tid]) ) \n",
    "            elif self.ictf_weight:\n",
    "                emb_and_score.append( (centroid, most_likely_tok, tid, ictfdict[tid]) )\n",
    "\n",
    "        return emb_and_score\n",
    "            \n",
    "\n",
    "    def KMedoids_clustering(self,prf_embs,prf_toks):\n",
    "        prf_embs = rmv_padding(prf_embs)\n",
    "        kmedoids = KMedoids(n_clusters=self.k, random_state=self.r, init='k-medoids++',method='pam').fit(prf_embs)\n",
    "        centroids = kmedoids.cluster_centers_\n",
    "        idx_centroid = kmedoids.medoid_indices_\n",
    "        \n",
    "        emb_and_score = []\n",
    "        for cluster in range(self.k):\n",
    "            centroid = kmedoids.cluster_centers_[cluster]\n",
    "            tid = prf_toks[idx_centroid[cluster]]\n",
    "            token = fnt.inference.query_tokenizer.tok.decode([tid])\n",
    "         \n",
    "            if self.mean_cos_weight:\n",
    "                emb_and_score.append( (centroid, token, tid, id2meancos[int(tid)]))\n",
    "            elif self.idf_weight:\n",
    "                emb_and_score.append( (centroid, token, tid, idfdict[int(tid)]) ) \n",
    "            elif self.ictf_weight:\n",
    "                emb_and_score.append( (centroid, token, tid, ictfdict[int(tid)]) ) \n",
    "        return emb_and_score\n",
    "    \n",
    "    def KMeansClosest_clustering(self,prf_embs):\n",
    "        prf_embs = rmv_padding(prf_embs)\n",
    "        kmn =  KMeans(self.k, random_state=self.r)\n",
    "        kmn.fit(prf_embs)\n",
    "        emb_and_score = []\n",
    "        D_Matrix = kmn.transform(prf_embs)\n",
    "        for cluster in range(self.k):\n",
    "            idx = np.argmin(D_Matrix[:,cluster])\n",
    "            centroid = np.float32(prf_embs[idx])\n",
    "            tid = fnt.emb2tid[idx]\n",
    "            centroid = kmn.cluster_centers_[cluster]\n",
    "            token = fnt.inference.query_tokenizer.tok.decode([tid])\n",
    "\n",
    "            if self.mean_cos_weight:\n",
    "                emb_and_score.append( (centroid, token, tid, id2meancos[int(tid)]))\n",
    "            elif self.idf_weight:\n",
    "                emb_and_score.append( (centroid, token, tid, idfdict[int(tid)]) ) \n",
    "            elif self.ictf_weight:\n",
    "                emb_and_score.append( (centroid, token, tid, ictfdict[int(tid)]) )  \n",
    "        return emb_and_score\n",
    "            \n",
    "\n",
    "    def transform_query(self, topic_and_res):\n",
    "        topic_and_res = topic_and_res.sort_values('rank')\n",
    "        if 'doc_embs' in topic_and_res.columns:\n",
    "            prf_embs = torch.cat(topic_and_res.head(self.fb_docs).doc_embs.tolist())\n",
    "        else:\n",
    "            prf_embs = torch.cat([factory.rrm.get_embedding(docid) for docid in topic_and_res.head(self.fb_docs).docid.values])\n",
    "\n",
    "        prf_toks = torch.cat([factory.nn_term().get_tokens_for_doc(docid) for docid in topic_and_res.head(self.fb_docs).docid.values])    \n",
    "\n",
    "\n",
    "        if self.kmeans:\n",
    "            emb_and_score = self.KMeans_clustering(prf_embs)\n",
    "        elif self.kmedoids:\n",
    "            emb_and_score = self.KMedoids_clustering(prf_embs,prf_toks)\n",
    "        elif self.kmeansclosest:\n",
    "            emb_and_score = self.KMeansClosest_clustering(prf_embs)\n",
    "        \n",
    "        \n",
    "        sorted_by_second = sorted(emb_and_score, key=lambda tup: -tup[3])\n",
    "        \n",
    "        exp_toks=[]\n",
    "        scores=[]\n",
    "        exp_embds = []\n",
    "        exp_tokens = []\n",
    "        \n",
    "        for i in range(min(self.exp_terms, len(sorted_by_second))):\n",
    "            emb, tok, tid, score = sorted_by_second[i]\n",
    "            exp_toks.append(tid)\n",
    "            exp_tokens.append(tok)\n",
    "\n",
    "\n",
    "            scores.append(score)\n",
    "            exp_embds.append(emb)\n",
    "        \n",
    "        first_row = topic_and_res.iloc[0]\n",
    "        \n",
    "        newtoks = torch.cat([first_row.query_toks,torch.tensor(exp_toks)])\n",
    "        newemb = torch.cat([\n",
    "            first_row.query_embs, \n",
    "            torch.Tensor(exp_embds)])\n",
    "        # apply weighting to the query embeddings\n",
    "        if self.mean_cos_weight or self.idf_weight or self.ictf_weight:\n",
    "            # we are using mean_cos weighting?\n",
    "            weights = torch.cat([ \n",
    "                torch.ones(len(first_row.query_embs)),\n",
    "                self.beta * torch.Tensor(scores)]\n",
    "            )\n",
    "        else:\n",
    "            weights = torch.cat([ \n",
    "                torch.ones(len(first_row.query_embs)),\n",
    "                torch.full(self.exp_terms, self.beta)]\n",
    "            )\n",
    "        \n",
    "        rtr = pd.DataFrame([\n",
    "            [first_row.qid, \n",
    "             first_row.docno,\n",
    "             first_row.query, \n",
    "             newemb, \n",
    "             newtoks,\n",
    "             exp_tokens, \n",
    "             weights ]], columns=[\"qid\",\"docno\", \"query\", \"query_embs\",\"query_toks\",\"expansion toks\",  \"query_weights\"])\n",
    "        return rtr\n",
    "        \n",
    "#         [\"qid\",\"query\",'docno','query_toks','query_embs']\n",
    "    def transform(self, topics_and_docs):\n",
    "        # some validation of the input\n",
    "        required = [\"qid\", \"query\", \"docid\",\"docno\", \"query_embs\",\"query_toks\"]\n",
    "        for col in required:\n",
    "            assert col in topics_and_docs.columns\n",
    "        #restore the docid column if missing\n",
    "        if \"docid\" not in topics_and_docs:\n",
    "            topics_and_docs[\"docid\"] = topics_and_docs.docid.astype(\"int\").values\n",
    "        rtr = []\n",
    "        for qid, res in topics_and_docs.groupby(\"qid\"):\n",
    "            new_query_df = self.transform_query(res)     \n",
    "            if self.return_docs:\n",
    "                new_query_df = res[[\"qid\", \"docno\", \"docid\"]].merge(new_query_df, on=[\"qid\"])\n",
    "                \n",
    "                new_query_df = new_query_df.rename(columns={'docno_x':'docno'})\n",
    "            rtr.append(new_query_df)\n",
    "        return pd.concat(rtr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-singles",
   "metadata": {},
   "source": [
    "# ColBERT-PRF Variants (measuring informativeness of expansion embeddings)\n",
    "- Now, we study the effectiveness of different informativeness measuring techniques, including, IDF, ICTF and MeanCos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "respected-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_kmeans_idf = (\n",
    "    factory.set_retrieve() >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)%10\n",
    "    >> ColbertPRF_variants(k=24, exp_terms=10, idf_weight=True, kmeans = True, kmedoids=False,kmeansclosest = False, beta=1,fb_docs=3)\n",
    "    >> factory.set_retrieve(query_encoded=True)>>factory.index_scorer(query_encoded=True,add_ranks=True)\n",
    ")\n",
    "\n",
    "prf_kmeans_ictf = (\n",
    "    factory.set_retrieve() >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)%10\n",
    "    >> ColbertPRF_variants(k=24, exp_terms=10, ictf_weight=True,kmeans = True, kmedoids=False,kmeansclosest = False, beta=1,fb_docs=3)\n",
    "    >> factory.set_retrieve(query_encoded=True)>>factory.index_scorer(query_encoded=True,add_ranks=True)\n",
    ")\n",
    "prf_kmeans_mcos = (\n",
    "    factory.set_retrieve() >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)%10\n",
    "    >> ColbertPRF_variants(k=24, exp_terms=10, mean_cos_weight=True,kmeans = True, kmedoids=False,kmeansclosest = False, beta=5,fb_docs=3)\n",
    "    >> factory.set_retrieve(query_encoded=True)>>factory.index_scorer(query_encoded=True,add_ranks=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "frank-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 129/129 [05:13<00:00,  2.43s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR(rel=2)</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@100</th>\n",
       "      <th>nDCG@1000</th>\n",
       "      <th>AP(rel=2)@100</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>R(rel=2)@100</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prf_kmeans_idf (beta=1)</td>\n",
       "      <td>0.885797</td>\n",
       "      <td>0.735153</td>\n",
       "      <td>0.690286</td>\n",
       "      <td>0.762042</td>\n",
       "      <td>0.481151</td>\n",
       "      <td>0.543161</td>\n",
       "      <td>0.670812</td>\n",
       "      <td>0.870633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prf_kmeans_ictf (beta=1)</td>\n",
       "      <td>0.872971</td>\n",
       "      <td>0.723230</td>\n",
       "      <td>0.672207</td>\n",
       "      <td>0.748912</td>\n",
       "      <td>0.466233</td>\n",
       "      <td>0.527005</td>\n",
       "      <td>0.654767</td>\n",
       "      <td>0.863237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prf_kmeans_mcos (beta=5)</td>\n",
       "      <td>0.864485</td>\n",
       "      <td>0.737531</td>\n",
       "      <td>0.691674</td>\n",
       "      <td>0.761707</td>\n",
       "      <td>0.483343</td>\n",
       "      <td>0.545149</td>\n",
       "      <td>0.669737</td>\n",
       "      <td>0.867126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  RR(rel=2)   nDCG@10  nDCG@100  nDCG@1000  \\\n",
       "0   prf_kmeans_idf (beta=1)   0.885797  0.735153  0.690286   0.762042   \n",
       "1  prf_kmeans_ictf (beta=1)   0.872971  0.723230  0.672207   0.748912   \n",
       "2  prf_kmeans_mcos (beta=5)   0.864485  0.737531  0.691674   0.761707   \n",
       "\n",
       "   AP(rel=2)@100  AP(rel=2)@1000  R(rel=2)@100  R(rel=2)@1000  \n",
       "0       0.481151        0.543161      0.670812       0.870633  \n",
       "1       0.466233        0.527005      0.654767       0.863237  \n",
       "2       0.483343        0.545149      0.669737       0.867126  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "pt.Experiment(\n",
    "    [\n",
    "    prf_kmeans_idf,\n",
    "    prf_kmeans_ictf,\n",
    "    prf_kmeans_mcos,\n",
    "\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=1, \n",
    "    verbose=True,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[RR(rel=2), nDCG@10, nDCG@100,nDCG@1000, AP(rel=2)@100,AP(rel=2)@1000,R(rel=2)@100,R(rel=2)@1000],\n",
    "    names=[\"prf_kmeans_idf (beta=1)\",\"prf_kmeans_ictf (beta=1)\",\"prf_kmeans_mcos (beta=5)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-strike",
   "metadata": {},
   "source": [
    "This table of results correspond to the results in Fig.10(a) of our Tweb paper. All the other results presented in Fig.10(b), (c) and (d) can be obtained with a similar setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-watts",
   "metadata": {},
   "source": [
    "# Effecient ColBERT-PRF Variants (A: ColBERT-PRF with different clustering technique)\n",
    "Here we demonstrate the effect of different clustering techniques on TREC DL 2019 test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "naked-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "e2e = factory.end_to_end()\n",
    "\n",
    "prf_kmedoids = (\n",
    "    factory.set_retrieve() >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)%10\n",
    "    >> ColbertPRF_variants(k=24, exp_terms=10, mean_cos_weight=False, idf_weight=True,kmedoids=True, beta=1,fb_docs=3)\n",
    "    >> factory.set_retrieve(query_encoded=True)>>factory.index_scorer(query_encoded=True,add_ranks=True)\n",
    ")\n",
    "\n",
    "prf_kmeans = (\n",
    "    factory.set_retrieve() >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)%10\n",
    "    >> ColbertPRF_variants(k=24, exp_terms=10, mean_cos_weight=False, idf_weight=True,kmeans = True, kmedoids=False,kmeansclosest = False, beta=1,fb_docs=3)\n",
    "    >> factory.set_retrieve(query_encoded=True)>>factory.index_scorer(query_encoded=True,add_ranks=True)\n",
    ")\n",
    "\n",
    "\n",
    "prf_kmeansclosest = (\n",
    "    factory.set_retrieve() >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)%10\n",
    "    >> ColbertPRF_variants(k=24, exp_terms=10, mean_cos_weight=False, idf_weight=True,kmeans = False, kmedoids=False,kmeansclosest = True, beta=1,fb_docs=3)\n",
    "    >> factory.set_retrieve(query_encoded=True)>>factory.index_scorer(query_encoded=True,add_ranks=True)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "convinced-windsor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 172/172 [04:54<00:00,  1.71s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR(rel=2)</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@100</th>\n",
       "      <th>nDCG@1000</th>\n",
       "      <th>AP(rel=2)@100</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>R(rel=2)@100</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2e</td>\n",
       "      <td>0.852883</td>\n",
       "      <td>0.693407</td>\n",
       "      <td>0.602954</td>\n",
       "      <td>0.672184</td>\n",
       "      <td>0.386995</td>\n",
       "      <td>0.430988</td>\n",
       "      <td>0.578838</td>\n",
       "      <td>0.789166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prf-kmeans</td>\n",
       "      <td>0.885797</td>\n",
       "      <td>0.735153</td>\n",
       "      <td>0.690286</td>\n",
       "      <td>0.762042</td>\n",
       "      <td>0.481151</td>\n",
       "      <td>0.543161</td>\n",
       "      <td>0.670812</td>\n",
       "      <td>0.870633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prf-kmedoids</td>\n",
       "      <td>0.872332</td>\n",
       "      <td>0.719888</td>\n",
       "      <td>0.666308</td>\n",
       "      <td>0.749149</td>\n",
       "      <td>0.443443</td>\n",
       "      <td>0.507308</td>\n",
       "      <td>0.655673</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prf-kmeansclosest</td>\n",
       "      <td>0.849663</td>\n",
       "      <td>0.729587</td>\n",
       "      <td>0.660544</td>\n",
       "      <td>0.729889</td>\n",
       "      <td>0.449797</td>\n",
       "      <td>0.507054</td>\n",
       "      <td>0.650107</td>\n",
       "      <td>0.850491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  RR(rel=2)   nDCG@10  nDCG@100  nDCG@1000  AP(rel=2)@100  \\\n",
       "0                e2e   0.852883  0.693407  0.602954   0.672184       0.386995   \n",
       "1         prf-kmeans   0.885797  0.735153  0.690286   0.762042       0.481151   \n",
       "2       prf-kmedoids   0.872332  0.719888  0.666308   0.749149       0.443443   \n",
       "3  prf-kmeansclosest   0.849663  0.729587  0.660544   0.729889       0.449797   \n",
       "\n",
       "   AP(rel=2)@1000  R(rel=2)@100  R(rel=2)@1000  \n",
       "0        0.430988      0.578838       0.789166  \n",
       "1        0.543161      0.670812       0.870633  \n",
       "2        0.507308      0.655673       0.868132  \n",
       "3        0.507054      0.650107       0.850491  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "pt.Experiment(\n",
    "    [\n",
    "    factory.end_to_end(),\n",
    "    prf_kmeans,\n",
    "    prf_kmedoids,\n",
    "    prf_kmeansclosest\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=1, \n",
    "    verbose=True,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[RR(rel=2), nDCG@10, nDCG@100,nDCG@1000, AP(rel=2)@100,AP(rel=2)@1000,R(rel=2)@100,R(rel=2)@1000],\n",
    "    names=[\"e2e\",\"prf-kmeans\",\"prf-kmedoids\",\"prf-kmeansclosest\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-middle",
   "metadata": {},
   "source": [
    "This table of results correspond to the results in Table 7 of our Tweb paper, in particular, the results for ColBERT-PRF ranking scenario on TREC 2019 query set. Experiments for reranking scenario pipelines and on TREC 2020 query set can be obtained with a similar setting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-improvement",
   "metadata": {},
   "source": [
    "\n",
    "# Efficient ColBERT-PRF Variants (B:  Approximate ANN ranking)\n",
    "-  Following the Approximate ANN ranking technique, proposed in [Macdonald21a]: On Approximate Nearest Neighbour Selection for Multi-Stage Dense Retrieval. Craig Macdonald and Nicola Tonellotto. In Proceedings of CIKM 2021. https://arxiv.org/abs/2108.11480\n",
    "\n",
    "- Here, we study the effectiveness and efficiency tradeoff using Approx. ANN ranking together with different clustering technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "worldwide-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_colbert.ranking import ColbertPRF\n",
    "prf_rank_approx_1stage = (factory.ann_retrieve_score()%300\\\n",
    "                   >> factory.index_scorer(query_encoded=True)\n",
    "                   >> factory.fetch_index_encodings(ids=True)\n",
    "                   >> ColbertPRF_variants(k=24, exp_terms=10, mean_cos_weight=False, idf_weight=True,kmeans=True, beta=1,fb_docs=3)\n",
    "                   >> factory.set_retrieve(query_encoded=True)\n",
    "                   >> (factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=5000) %1000))\n",
    "\n",
    "prf_rank_approx_13stage = (factory.ann_retrieve_score()%300\n",
    "                   >> factory.index_scorer(query_encoded=True)>> factory.fetch_index_encodings(ids=True)\n",
    "                   >> ColbertPRF_variants(k=24, exp_terms=10, mean_cos_weight=False, idf_weight=True,kmeans=True, beta=1,fb_docs=3)\n",
    "                   >> factory.ann_retrieve_score(query_encoded=True)%1000\n",
    "                   >> (factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=5000) %1000))\n",
    "\n",
    "prf_rerank_approx =(factory.ann_retrieve_score()%1000\n",
    "                >> factory.index_scorer(query_encoded=True)>> factory.fetch_index_encodings(ids=True)\n",
    "                >> ColbertPRF_variants(k=24, exp_terms=10, mean_cos_weight=False, idf_weight=True,kmeans=True, beta=1,fb_docs=3,return_docs=True)\n",
    "                >> (factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=5000) %1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "modern-outline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 129/129 [03:20<00:00,  1.55s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR(rel=2)</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@100</th>\n",
       "      <th>nDCG@1000</th>\n",
       "      <th>AP(rel=2)@100</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>R(rel=2)@100</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann_kmeans_ranker.1stage</td>\n",
       "      <td>0.864880</td>\n",
       "      <td>0.731379</td>\n",
       "      <td>0.690439</td>\n",
       "      <td>0.763278</td>\n",
       "      <td>0.483502</td>\n",
       "      <td>0.546565</td>\n",
       "      <td>0.666271</td>\n",
       "      <td>0.869528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ann_kmeans_ranker.13stage</td>\n",
       "      <td>0.864631</td>\n",
       "      <td>0.731379</td>\n",
       "      <td>0.679103</td>\n",
       "      <td>0.718573</td>\n",
       "      <td>0.474658</td>\n",
       "      <td>0.519824</td>\n",
       "      <td>0.652961</td>\n",
       "      <td>0.804410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ann_kmeans_reranker</td>\n",
       "      <td>0.885826</td>\n",
       "      <td>0.732971</td>\n",
       "      <td>0.623566</td>\n",
       "      <td>0.637119</td>\n",
       "      <td>0.423349</td>\n",
       "      <td>0.456489</td>\n",
       "      <td>0.585278</td>\n",
       "      <td>0.695251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  RR(rel=2)   nDCG@10  nDCG@100  nDCG@1000  \\\n",
       "0   ann_kmeans_ranker.1stage   0.864880  0.731379  0.690439   0.763278   \n",
       "1  ann_kmeans_ranker.13stage   0.864631  0.731379  0.679103   0.718573   \n",
       "2        ann_kmeans_reranker   0.885826  0.732971  0.623566   0.637119   \n",
       "\n",
       "   AP(rel=2)@100  AP(rel=2)@1000  R(rel=2)@100  R(rel=2)@1000  \n",
       "0       0.483502        0.546565      0.666271       0.869528  \n",
       "1       0.474658        0.519824      0.652961       0.804410  \n",
       "2       0.423349        0.456489      0.585278       0.695251  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "pt.Experiment(\n",
    "    [\n",
    "    prf_rank_approx_1stage,\n",
    "    prf_rank_approx_13stage,\n",
    "    prf_rerank_approx\n",
    "\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=1, \n",
    "    verbose=True,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[RR(rel=2), nDCG@10, nDCG@100,nDCG@1000, AP(rel=2)@100,AP(rel=2)@1000,R(rel=2)@100,R(rel=2)@1000],\n",
    "    names=[\"ann_kmeans_ranker.1stage\",\"ann_kmeans_ranker.13stage\",\"ann_kmeans_reranker\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-shame",
   "metadata": {},
   "source": [
    "This table of results correspond to the results in Table 7 of our Tweb paper, in particular, the results for ColBERT-PRF implemented with KMeans clustering as well as the Approximate Scoring technique on TREC 2019 query set. \n",
    "\n",
    "Experiments on TREC 2020 query set can be obtained with a similar setting. \n",
    "\n",
    "In addition, for expriments apply Approximate Scoring technique together with KMeansClosest or KMedoids clustering technique for ColBERT-PRF can also be obtained with a similar setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-cleaning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
